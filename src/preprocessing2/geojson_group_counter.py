"""
ğŸ“Œ GeoJSON ê¸°ë°˜ ìœ„ê²½ë„ â†’ í–‰ì •ë™ ë§¤í•‘ ë° ê°œìˆ˜ ì§‘ê³„ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì„œìš¸ì‹œ í–‰ì •ë™ GeoJSON ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬
data/raw/ í´ë” ë‚´ ì§€ì •ëœ ì›ì‹œ ë°ì´í„°(*__raw.csv ë˜ëŠ” .xlsx)ì˜
ìœ„ë„(latitude), ê²½ë„(longitude) ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ
ê° ìì¹˜êµ¬/í–‰ì •ë™ ë‹¨ìœ„ë¡œ ë§¤í•‘ ë° ê°œìˆ˜ ì§‘ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

ğŸ”§ ì£¼ìš” ê¸°ëŠ¥:
- ìœ„ê²½ë„ â†’ í–‰ì •ë™ ë§¤í•‘ (GeoJSON ê¸°ë°˜ ê³µê°„ í¬í•¨ ì—¬ë¶€ íŒë³„)
- ìì¹˜êµ¬ì½”ë“œ(gu_code), í–‰ì •ë™ì½”ë“œ(dong_code) ê¸°ì¤€ ê°œìˆ˜ ì§‘ê³„
- ìì¹˜êµ¬ëª…/ë™ëª…ì€ ë³´ì¡°ì •ë³´ë¡œ í¬í•¨
- ì²˜ë¦¬ ìš”ì•½ (__summary.csv) ì €ì¥ í¬í•¨
- ì „ì²´ ì‹¤í–‰ì‹œê°„ ì¸¡ì • ë° í‘œì‹œ

ğŸ“‚ ì…ë ¥ ê²½ë¡œ:
- ë°ì´í„°:        data/raw/*__raw.csv ë˜ëŠ” *__raw.xlsx
- ì°¸ì¡° GeoJSON:  data/reference/Seoul_HangJeongDong.geojson

ğŸ“ ì¶œë ¥ ê²½ë¡œ:
- ê²°ê³¼ CSV:     data/processed_counts2/{íŒŒì¼ëª…__counts.csv}
- ì²˜ë¦¬ ìš”ì•½:    data/processed_counts2/__summary.csv

âš ï¸ ì‹¤í–‰ ì£¼ì˜:
- PyCharmì—ì„œ ì‹¤í–‰ ì‹œ, ê¸°ë³¸ working directoryê°€ src/preprocessing2ë¡œ ì„¤ì •ë¨.
  ë”°ë¼ì„œ ê²½ë¡œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ os.chdirë¥¼ í†µí•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ì½”ë“œ í¬í•¨.
- ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª…("ìœ„ë„", "LATITUDE", "ë³‘ì›ìœ„ë„" ë“±)ì„ ìë™ ê°ì§€í•˜ì—¬ ì²˜ë¦¬.

âœ… ì‹¤í–‰ í™˜ê²½: **PyCharm ì‹¤í–‰**

ì‘ì„±ì: ê°•ë¯¼í˜
"""
import os
import sys
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from tqdm import tqdm
import time
from datetime import datetime

# ğŸ• ì‹¤í–‰ ì‹œì‘ ì‹œê°„ ê¸°ë¡
start_time = time.time()
start_datetime = datetime.now()

print(f"ğŸš€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œì‘: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")

# ğŸ” í•­ìƒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œê°€ ë§ì¶°ì§€ë„ë¡ ì„¤ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
os.chdir(project_root)
sys.path.append(os.path.join(project_root, "src"))

# âœ… ê²½ë¡œ ì„¤ì •
RAW_DIR = "data/raw"
OUTPUT_DIR = "data/processed_counts2"
GEOJSON_PATH = "data/reference/Seoul_HangJeongDong.geojson"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# âœ… ì²˜ë¦¬í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸
TARGET_FILES = [
    "bus_stop__raw.csv",
    "cctv__raw.csv",
    "hospital__raw.csv",
    "library__raw.csv",
    "park__raw.csv",
    "safety_bell__raw.xlsx",  # ì—‘ì…€ë„ í¬í•¨ë¨
    "street_light__raw.csv",
    "subway_station__raw.csv"
]

# âœ… GeoJSON ë¡œë”©
print("ğŸ“ GeoJSON ë¡œë”© ì¤‘...")
geojson_start = time.time()
gdf = gpd.read_file(GEOJSON_PATH).to_crs(epsg=4326)
geojson_load_time = time.time() - geojson_start
print(f"âœ… GeoJSON ë¡œë”© ì™„ë£Œ ({geojson_load_time:.2f}ì´ˆ)")

# âœ… GeoJSON ê¸°ë°˜ ë™ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜
def get_dong_info_by_coords(lon, lat):
    try:
        point = Point(float(lon), float(lat))
        for _, row in gdf.iterrows():
            if row["geometry"].contains(point):
                props = row["properties"] if "properties" in row else row
                return {
                    "gu_code": props["sgg"],
                    "dong_code": props["adm_cd2"],
                    "gu_name": props["sggnm"],
                    "dong_name": props["adm_nm"].split()[-1],
                }
        return None  # í¬í•¨ ì•ˆë¨
    except Exception as e:
        print(f"[âŒ ë§¤í•‘ ì˜¤ë¥˜] ìœ„ë„: {lat}, ê²½ë„: {lon} â†’ {e}")
        return None

# âœ… tqdm ì„¤ì •
tqdm.pandas()

summary_rows = []
total_processed_files = 0
total_processed_rows = 0

# âœ… ê° íŒŒì¼ ë°˜ë³µ ì²˜ë¦¬
for filename in TARGET_FILES:
    input_path = os.path.join(RAW_DIR, filename)
    if not os.path.exists(input_path):
        print(f"[âŒ ì—†ìŒ] {filename} â†’ ê±´ë„ˆëœ€")
        continue

    print(f"\n[ğŸ”„ ì²˜ë¦¬ ì¤‘] {filename}")
    file_start_time = time.time()

    # âœ… íŒŒì¼ í™•ì¥ì êµ¬ë¶„
    try:
        if filename.endswith(".csv"):
            try:
                df = pd.read_csv(input_path, dtype=str, encoding="utf-8")
            except UnicodeDecodeError:
                print(f"[âš ï¸ ì¸ì½”ë”© ì¬ì‹œë„] {filename} â†’ cp949ë¡œ ë‹¤ì‹œ ì‹œë„")
                df = pd.read_csv(input_path, dtype=str, encoding="cp949")
        elif filename.endswith(".xlsx"):
            df = pd.read_excel(input_path, dtype=str)
        else:
            print(f"[âš ï¸ í™•ì¥ì ë¯¸ì§€ì›] {filename}")
            continue
    except Exception as e:
        print(f"[âŒ ì½ê¸° ì‹¤íŒ¨] {filename} â†’ {e}")
        continue

    total_rows = len(df)
    total_processed_rows += total_rows

    # âœ… ê²½ë„/ìœ„ë„ ì»¬ëŸ¼ ìë™ ê°ì§€ (ì‚¬ìš©ì ì§€ì • í›„ë³´ í¬í•¨)
    lon_col = next(
        (col for col in df.columns if col in ["ê²½ë„", "LONGITUDE", "longitude", "XCRD", "ë³‘ì›ê²½ë„", "WGS84ê²½ë„"])
        , None
    )
    lat_col = next(
        (col for col in df.columns if col in ["ìœ„ë„", "LATITUDE", "latitude", "YCRD", "ë³‘ì›ìœ„ë„", "WGS84ìœ„ë„"])
        , None
    )

    if not lon_col or not lat_col:
        print(f"[âš ï¸ ìŠ¤í‚µ] {filename} â†’ ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ ì—†ìŒ")
        summary_rows.append({
            "filename": filename,
            "total_rows": total_rows,
            "matched_rows": 0,
            "success_rate": 0.0,
            "processing_time": 0.0
        })
        continue

    # âœ… ë™ ì •ë³´ ì¶”ì¶œ
    mapping_start = time.time()
    info_series = df[[lon_col, lat_col]].progress_apply(
        lambda row: get_dong_info_by_coords(row[lon_col], row[lat_col]) or {}, axis=1
    )
    mapping_time = time.time() - mapping_start

    info_df = pd.DataFrame(info_series.tolist())
    result_df = pd.concat([df, info_df], axis=1)

    # âœ… ìœ íš¨ ë§¤í•‘ í•„í„°ë§
    matched_df = result_df.dropna(subset=["gu_code", "dong_code"])
    matched_rows = len(matched_df)
    success_rate = (matched_rows / total_rows) * 100 if total_rows > 0 else 0

    file_processing_time = time.time() - file_start_time

    print(f"ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {total_rows}")
    print(f"âœ… ë§¤í•‘ ì„±ê³µ í–‰ ìˆ˜: {matched_rows}")
    print(f"ğŸ¯ ë§¤í•‘ ì„±ê³µë¥ : {success_rate:.2f}%")
    print(f"â±ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹œê°„: {file_processing_time:.2f}ì´ˆ (ë§¤í•‘: {mapping_time:.2f}ì´ˆ)")

    summary_rows.append({
        "filename": filename,
        "total_rows": total_rows,
        "matched_rows": matched_rows,
        "success_rate": round(success_rate, 2),
        "processing_time": round(file_processing_time, 2)
    })

    if matched_rows == 0:
        print(f"[âš ï¸ ìŠ¤í‚µ] {filename} â†’ ë§¤í•‘ëœ ë°ì´í„° ì—†ìŒ")
        continue

    # âœ… ìì¹˜êµ¬ì½”ë“œ + í–‰ì •ë™ì½”ë“œ ê¸°ì¤€ ê°œìˆ˜ ì§‘ê³„
    count_df = (
        matched_df.groupby(["gu_code", "dong_code", "gu_name", "dong_name"])
        .size()
        .reset_index(name="counts")
    )

    # âœ… ì €ì¥
    output_filename = filename.replace("__raw.xlsx", "__counts.csv").replace("__raw.csv", "__counts.csv")
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    count_df.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"[ğŸ’¾ ì €ì¥ ì™„ë£Œ] {output_path}")

    total_processed_files += 1

# âœ… ì „ì²´ ìš”ì•½ ì €ì¥
summary_df = pd.DataFrame(summary_rows)
summary_path = os.path.join(OUTPUT_DIR, "__summary.csv")
summary_df.to_csv(summary_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ“‹ ì²˜ë¦¬ ìš”ì•½ ì €ì¥ ì™„ë£Œ â†’ {summary_path}")

# ğŸ• ì‹¤í–‰ ì¢…ë£Œ ì‹œê°„ ë° ì´ ì†Œìš” ì‹œê°„ ê³„ì‚°
end_time = time.time()
end_datetime = datetime.now()
total_execution_time = end_time - start_time

# ì‹œê°„ í¬ë§·íŒ… (ì‹œ:ë¶„:ì´ˆ)
hours = int(total_execution_time // 3600)
minutes = int((total_execution_time % 3600) // 60)
seconds = int(total_execution_time % 60)

print(f"\n" + "="*60)
print(f"ğŸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
print(f"   - ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {total_processed_files}ê°œ")
print(f"   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: {total_processed_rows:,}ê°œ")
print(f"   - ì „ì²´ ì‹¤í–‰ ì‹œê°„: {hours:02d}:{minutes:02d}:{seconds:02d} ({total_execution_time:.2f}ì´ˆ)")
print(f"   - í‰ê·  ì²˜ë¦¬ ì†ë„: {total_processed_rows/total_execution_time:.1f} í–‰/ì´ˆ")
print("="*60)
