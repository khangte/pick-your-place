"""
ğŸ“Œ ì„œìš¸ì‹œ GeoJSON ê¸°ì¤€ ìœ„ê²½ë„ â†’ í–‰ì •ë™ ê³µê°„ ì¡°ì¸ í›„ ê°œìˆ˜ ì§‘ê³„
- íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- ìœ„ê²½ë„ ì»¬ëŸ¼ ìë™ ê°ì§€
- sjoinì„ í™œìš©í•œ ê³ ì† ê³µê°„ ë§¤í•‘
- ì‹¤íŒ¨í•œ í–‰ì€ ë³„ë„ë¡œ ì €ì¥ (e.g., __failed.csv)
- ì„œìš¸ ì™¸ ì§€ì—­ë„ ì‹ë³„í•˜ì—¬ ì œì™¸ (ì˜ˆ: subway_station)
- ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ í¬í•¨

ğŸ§ª ê°œë°œí™˜ê²½: PyCharm ì‹¤í–‰ ê¸°ì¤€
"""

import os
import sys
import time
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from tqdm import tqdm

# ğŸ” í•­ìƒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œê°€ ë§ì¶°ì§€ë„ë¡ ì„¤ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
os.chdir(project_root)
sys.path.append(os.path.join(project_root, "src"))

# âœ… ê²½ë¡œ ì„¤ì •
INPUT_DIR = "data/raw"
OUTPUT_DIR = "data/processed_counts2"
GEOJSON_PATH = "data/reference/Seoul_HangJeongDong.geojson"
FULL_GEOJSON_PATH = "data/reference/HangJeongDong_ver20250401.geojson"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# âœ… ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ ëª©ë¡
TARGET_FILES = [
    "bus_stop__raw.csv",
    "cctv__raw.csv",
    "hospital__raw.csv",
    "library__raw.csv",
    "park__raw.csv",
    "safety_bell__raw.xlsx",
    "street_light__raw.csv",
    "subway_station__raw.csv"
]

# âœ… GeoJSON ë¡œë“œ
gdf = gpd.read_file(GEOJSON_PATH).to_crs(epsg=4326)

# âœ… ì „ì²´ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
summary_list = []

# âœ… ì „ì²´ ì‹œì‘ ì‹œê°„
total_start = time.time()

for filename in TARGET_FILES:
    start_time = time.time()
    print(f"\n[ğŸ”„ ì²˜ë¦¬ ì¤‘] {filename}")
    file_path = os.path.join(INPUT_DIR, filename)

    # âœ… íŒŒì¼ ì½ê¸°
    try:
        if filename.endswith(".csv"):
            try:
                df = pd.read_csv(file_path, dtype=str)
            except UnicodeDecodeError:
                print(f"[âš ï¸ ì¸ì½”ë”© ì¬ì‹œë„] {filename} â†’ cp949")
                df = pd.read_csv(file_path, dtype=str, encoding="cp949")
        elif filename.endswith(".xlsx"):
            df = pd.read_excel(file_path, dtype=str)
        else:
            print(f"[âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹] {filename}")
            continue
    except Exception as e:
        print(f"[âŒ ì½ê¸° ì‹¤íŒ¨] {filename} â†’ {e}")
        continue

    # âœ… ê²½ë„/ìœ„ë„ ì»¬ëŸ¼ ìë™ íƒìƒ‰
    lon_col = next((col for col in df.columns if col.lower() in ["ê²½ë„", "longitude", "xcrd", "ë³‘ì›ê²½ë„", "wgs84ê²½ë„"]), None)
    lat_col = next((col for col in df.columns if col.lower() in ["ìœ„ë„", "latitude", "ycrd", "ë³‘ì›ìœ„ë„", "wgs84ìœ„ë„"]), None)

    if not lon_col or not lat_col:
        print(f"[âŒ ê²½ìœ„ë„ ì»¬ëŸ¼ ì—†ìŒ] {filename}")
        continue

    # âœ… ìœ„ê²½ë„ â†’ Point ê°ì²´ ìƒì„±
    df[lon_col] = df[lon_col].astype(float)
    df[lat_col] = df[lat_col].astype(float)
    df["geometry"] = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]
    gdf_points = gpd.GeoDataFrame(df, geometry="geometry", crs="EPSG:4326")

    # âœ… ê³µê°„ ì¡°ì¸
    joined = gpd.sjoin(gdf_points, gdf, how="left", predicate="within")

    # âœ… ì„œìš¸ ì—¬ë¶€ í™•ì¸ (subway_stationë§Œ ì˜ˆì™¸ ì²˜ë¦¬)
    if "subway_station" in filename:
        full_gdf = gpd.read_file(FULL_GEOJSON_PATH).to_crs(epsg=4326)
        full_joined = gpd.sjoin(gdf_points, full_gdf, how="left", predicate="within")
        joined["sidonm"] = full_joined["sidonm"]

        # ì„œìš¸ ì•„ë‹Œ ê²½ìš° ì‹¤íŒ¨ ì²˜ë¦¬
        failed_rows = joined[joined["sidonm"] != "ì„œìš¸íŠ¹ë³„ì‹œ"]
        joined = joined[joined["sidonm"] == "ì„œìš¸íŠ¹ë³„ì‹œ"]
    else:
        failed_rows = joined[joined["adm_nm"].isna()]
        joined = joined[~joined["adm_nm"].isna()]

    # âœ… ì»¬ëŸ¼ ë¶„ë¦¬ ë° ì§‘ê³„
    joined["gu_name"] = joined["adm_nm"].str.split().str[1]
    joined["dong_name"] = joined["adm_nm"].str.split().str[2]
    joined["gu_code"] = joined["adm_cd2"].str[:5]
    joined["dong_code"] = joined["adm_cd2"]

    counts = (
        joined.groupby(["gu_code", "dong_code", "gu_name", "dong_name"])
        .size()
        .reset_index(name="counts")
        .sort_values("counts", ascending=False)
    )

    # âœ… ì €ì¥
    name_prefix = filename.replace("__raw.csv", "").replace("__raw.xlsx", "")
    counts_path = os.path.join(OUTPUT_DIR, f"{name_prefix}__counts.csv")
    counts.to_csv(counts_path, index=False, encoding="utf-8-sig")
    print(f"[ğŸ’¾ ì €ì¥ ì™„ë£Œ] {counts_path}")

    # âœ… ì‹¤íŒ¨ ë°ì´í„° ì €ì¥
    if not failed_rows.empty:
        failed_path = os.path.join(OUTPUT_DIR, f"{name_prefix}__failed.csv")
        failed_rows.drop(columns=["index_right"], errors="ignore").to_csv(
            failed_path, index=False, encoding="utf-8-sig"
        )
        print(f"[âš ï¸ ì‹¤íŒ¨ ë°ì´í„° ì €ì¥] {failed_path} ({len(failed_rows)} rows)")

    # âœ… ë¡œê·¸ ì¶œë ¥ ë° ìš”ì•½ ì €ì¥
    elapsed = time.time() - start_time
    print(f"ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {len(df)}")
    print(f"âœ… ë§¤í•‘ ì„±ê³µ í–‰ ìˆ˜: {len(joined)}")
    print(f"ğŸ¯ ë§¤í•‘ ì„±ê³µë¥ : {len(joined) / len(df) * 100:.2f}%")
    print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")

    summary_list.append({
        "filename": filename,
        "total_rows": len(df),
        "mapped_rows": len(joined),
        "success_rate": round(len(joined) / len(df) * 100, 2),
        "time_sec": round(elapsed, 2)
    })

# âœ… ì „ì²´ ì²˜ë¦¬ ì‹œê°„
total_elapsed = time.time() - total_start
print(f"\nâœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.2f}ì´ˆ")

# âœ… ìš”ì•½ ì €ì¥
summary_df = pd.DataFrame(summary_list)
summary_path = os.path.join(OUTPUT_DIR, "__summary.csv")
summary_df.to_csv(summary_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ“‹ ì „ì²´ ìš”ì•½ ì €ì¥ ì™„ë£Œ â†’ {summary_path}")

