"""
ğŸ“Œ ì„œìš¸ì‹œ GeoJSON ê¸°ì¤€ ìœ„ê²½ë„ â†’ í–‰ì •ë™ ê³µê°„ ì¡°ì¸ í›„ ê°œìˆ˜ ì§‘ê³„
- íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- ìœ„ê²½ë„ ì»¬ëŸ¼ ìë™ ê°ì§€
- sjoinì„ í™œìš©í•œ ê³ ì† ê³µê°„ ë§¤í•‘
- ì‹¤íŒ¨í•œ í–‰ì€ ë³„ë„ë¡œ ì €ì¥ (e.g., __failed.csv)
- ì„œìš¸ ì™¸ ì§€ì—­ë„ ì‹ë³„í•˜ì—¬ ì œì™¸ (ì˜ˆ: subway_station)
- ìƒì„¸ ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ í¬í•¨

ğŸ§ª ê°œë°œí™˜ê²½: PyCharm ì‹¤í–‰ ê¸°ì¤€
"""

import os
import sys
import time
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from tqdm import tqdm
from datetime import datetime

# ğŸ• ì‹¤í–‰ ì‹œì‘ ì‹œê°„ ê¸°ë¡
script_start_time = time.time()
start_datetime = datetime.now()

print(f"ğŸš€ ê³µê°„ ì¡°ì¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œì‘: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")

# ğŸ” í•­ìƒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œê°€ ë§ì¶°ì§€ë„ë¡ ì„¤ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
os.chdir(project_root)
sys.path.append(os.path.join(project_root, "src"))

# âœ… ê²½ë¡œ ì„¤ì •
INPUT_DIR = "data/raw"
OUTPUT_DIR = "data/processed_counts2"
GEOJSON_PATH = "data/reference/Seoul_HangJeongDong.geojson"
FULL_GEOJSON_PATH = "data/reference/HangJeongDong_ver20250401.geojson"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# âœ… ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ ëª©ë¡
TARGET_FILES = [
    "bus_stop__raw.csv",
    "cctv__raw.csv",
    "hospital__raw.csv",
    "library__raw.csv",
    "park__raw.csv",
    "safety_bell__raw.xlsx",
    "street_light__raw.csv",
    "subway_station__raw.csv"
]

# âœ… GeoJSON ë¡œë“œ
print("ğŸ“ ì„œìš¸ì‹œ GeoJSON ë¡œë”© ì¤‘...")
geojson_start = time.time()
gdf = gpd.read_file(GEOJSON_PATH).to_crs(epsg=4326)
geojson_load_time = time.time() - geojson_start
print(f"âœ… ì„œìš¸ì‹œ GeoJSON ë¡œë”© ì™„ë£Œ ({geojson_load_time:.2f}ì´ˆ)")

# âœ… ì „ì²´ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
summary_list = []
total_processed_files = 0
total_processed_rows = 0
total_mapped_rows = 0

# âœ… ì „ì²´ ì‹œì‘ ì‹œê°„
total_start = time.time()

for filename in TARGET_FILES:
    file_start_time = time.time()
    print(f"\n[ğŸ”„ ì²˜ë¦¬ ì¤‘] {filename}")
    file_path = os.path.join(INPUT_DIR, filename)

    # âœ… íŒŒì¼ ì½ê¸°
    try:
        read_start = time.time()
        if filename.endswith(".csv"):
            try:
                df = pd.read_csv(file_path, dtype=str)
            except UnicodeDecodeError:
                print(f"[âš ï¸ ì¸ì½”ë”© ì¬ì‹œë„] {filename} â†’ cp949")
                df = pd.read_csv(file_path, dtype=str, encoding="cp949")
        elif filename.endswith(".xlsx"):
            df = pd.read_excel(file_path, dtype=str)
        else:
            print(f"[âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹] {filename}")
            continue
        read_time = time.time() - read_start
        print(f"   ğŸ“– íŒŒì¼ ì½ê¸° ì™„ë£Œ ({read_time:.2f}ì´ˆ)")
    except Exception as e:
        print(f"[âŒ ì½ê¸° ì‹¤íŒ¨] {filename} â†’ {e}")
        continue

    # âœ… ê²½ë„/ìœ„ë„ ì»¬ëŸ¼ ìë™ íƒìƒ‰
    lon_col = next((col for col in df.columns if col.lower() in ["ê²½ë„", "longitude", "xcrd", "ë³‘ì›ê²½ë„", "wgs84ê²½ë„"]), None)
    lat_col = next((col for col in df.columns if col.lower() in ["ìœ„ë„", "latitude", "ycrd", "ë³‘ì›ìœ„ë„", "wgs84ìœ„ë„"]), None)

    if not lon_col or not lat_col:
        print(f"[âŒ ê²½ìœ„ë„ ì»¬ëŸ¼ ì—†ìŒ] {filename}")
        continue

    # âœ… ìœ„ê²½ë„ â†’ Point ê°ì²´ ìƒì„±
    geometry_start = time.time()
    df[lon_col] = df[lon_col].astype(float)
    df[lat_col] = df[lat_col].astype(float)

    df["geometry"] = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]
    gdf_points = gpd.GeoDataFrame(df, geometry="geometry", crs="EPSG:4326")
    geometry_time = time.time() - geometry_start
    print(f"   ğŸ—ºï¸ ì§€ì˜¤ë©”íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ ({geometry_time:.2f}ì´ˆ)")

    # âœ… ê³µê°„ ì¡°ì¸
    join_start = time.time()
    joined = gpd.sjoin(gdf_points, gdf, how="left", predicate="within")
    join_time = time.time() - join_start
    print(f"   ğŸ”— ê³µê°„ ì¡°ì¸ ì™„ë£Œ ({join_time:.2f}ì´ˆ)")

    # âœ… ì„œìš¸ ì—¬ë¶€ í™•ì¸ (subway_stationë§Œ ì˜ˆì™¸ ì²˜ë¦¬)
    if "subway_station" in filename:
        print("   ğŸš‡ ì§€í•˜ì² ì—­ - ì „êµ­ GeoJSONìœ¼ë¡œ ì„œìš¸ ì™¸ ì§€ì—­ í•„í„°ë§ ì¤‘...")
        full_join_start = time.time()
        full_gdf = gpd.read_file(FULL_GEOJSON_PATH).to_crs(epsg=4326)
        full_joined = gpd.sjoin(gdf_points, full_gdf, how="left", predicate="within")
        joined["sidonm"] = full_joined["sidonm"]

        # ì„œìš¸ ì•„ë‹Œ ê²½ìš° ì‹¤íŒ¨ ì²˜ë¦¬
        failed_rows = joined[joined["sidonm"] != "ì„œìš¸íŠ¹ë³„ì‹œ"]
        joined = joined[joined["sidonm"] == "ì„œìš¸íŠ¹ë³„ì‹œ"]
        full_join_time = time.time() - full_join_start
        print(f"   ğŸŒ ì „êµ­ ì¡°ì¸ ë° í•„í„°ë§ ì™„ë£Œ ({full_join_time:.2f}ì´ˆ)")
    else:
        failed_rows = joined[joined["adm_nm"].isna()]
        joined = joined[~joined["adm_nm"].isna()]

    # âœ… ì»¬ëŸ¼ ë¶„ë¦¬ ë° ì§‘ê³„
    processing_start = time.time()
    joined["gu_name"] = joined["adm_nm"].str.split().str[1]
    joined["dong_name"] = joined["adm_nm"].str.split().str[2]
    joined["gu_code"] = joined["adm_cd2"].str[:5]
    joined["dong_code"] = joined["adm_cd2"]

    counts = (
        joined.groupby(["gu_code", "dong_code", "gu_name", "dong_name"])
        .size()
        .reset_index(name="counts")
        .sort_values("counts", ascending=False)
    )
    processing_time = time.time() - processing_start
    print(f"   ğŸ“Š ë°ì´í„° ì²˜ë¦¬ ë° ì§‘ê³„ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")

    # âœ… ì €ì¥
    save_start = time.time()
    name_prefix = filename.replace("__raw.csv", "").replace("__raw.xlsx", "")
    counts_path = os.path.join(OUTPUT_DIR, f"{name_prefix}__counts.csv")
    counts.to_csv(counts_path, index=False, encoding="utf-8-sig")

    # âœ… ì‹¤íŒ¨ ë°ì´í„° ì €ì¥
    if not failed_rows.empty:
        failed_path = os.path.join(OUTPUT_DIR, f"{name_prefix}__failed.csv")
        failed_rows.drop(columns=["index_right"], errors="ignore").to_csv(
            failed_path, index=False, encoding="utf-8-sig"
        )
        print(f"   âš ï¸ ì‹¤íŒ¨ ë°ì´í„° ì €ì¥: {failed_path} ({len(failed_rows)} rows)")

    save_time = time.time() - save_start
    print(f"   ğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ ({save_time:.2f}ì´ˆ)")

    # âœ… ë¡œê·¸ ì¶œë ¥ ë° ìš”ì•½ ì €ì¥
    file_elapsed = time.time() - file_start_time
    success_rate = len(joined) / len(df) * 100 if len(df) > 0 else 0

    print(f"ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {len(df):,}")
    print(f"âœ… ë§¤í•‘ ì„±ê³µ í–‰ ìˆ˜: {len(joined):,}")
    print(f"ğŸ¯ ë§¤í•‘ ì„±ê³µë¥ : {success_rate:.2f}%")
    print(f"â±ï¸ ì´ íŒŒì¼ ì²˜ë¦¬ ì‹œê°„: {file_elapsed:.2f}ì´ˆ")

    # ë‹¨ê³„ë³„ ì‹œê°„ ë¹„ìœ¨ ê³„ì‚°
    print(f"   â””â”€ ì½ê¸°: {read_time:.2f}ì´ˆ ({read_time/file_elapsed*100:.1f}%)")
    print(f"   â””â”€ ì§€ì˜¤ë©”íŠ¸ë¦¬: {geometry_time:.2f}ì´ˆ ({geometry_time/file_elapsed*100:.1f}%)")
    print(f"   â””â”€ ì¡°ì¸: {join_time:.2f}ì´ˆ ({join_time/file_elapsed*100:.1f}%)")
    if "subway_station" in filename:
        print(f"   â””â”€ ì „êµ­ì¡°ì¸: {full_join_time:.2f}ì´ˆ ({full_join_time/file_elapsed*100:.1f}%)")
    print(f"   â””â”€ ì²˜ë¦¬: {processing_time:.2f}ì´ˆ ({processing_time/file_elapsed*100:.1f}%)")
    print(f"   â””â”€ ì €ì¥: {save_time:.2f}ì´ˆ ({save_time/file_elapsed*100:.1f}%)")

    summary_list.append({
        "filename": filename,
        "total_rows": len(df),
        "mapped_rows": len(joined),
        "failed_rows": len(failed_rows),
        "success_rate": round(success_rate, 2),
        "time_sec": round(file_elapsed, 2),
        "read_time": round(read_time, 2),
        "geometry_time": round(geometry_time, 2),
        "join_time": round(join_time, 2),
        "processing_time": round(processing_time, 2),
        "save_time": round(save_time, 2)
    })

    total_processed_files += 1
    total_processed_rows += len(df)
    total_mapped_rows += len(joined)

# âœ… ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
total_elapsed = time.time() - total_start
script_total_time = time.time() - script_start_time
end_datetime = datetime.now()

# ì‹œê°„ í¬ë§·íŒ…
hours = int(script_total_time // 3600)
minutes = int((script_total_time % 3600) // 60)
seconds = int(script_total_time % 60)

print(f"\n" + "="*70)
print(f"ğŸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
print(f"   - ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {total_processed_files}ê°œ")
print(f"   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: {total_processed_rows:,}ê°œ")
print(f"   - ì´ ë§¤í•‘ ì„±ê³µ í–‰ ìˆ˜: {total_mapped_rows:,}ê°œ")
print(f"   - ì „ì²´ ì„±ê³µë¥ : {total_mapped_rows/total_processed_rows*100:.2f}%")
print(f"   - ë°ì´í„° ì²˜ë¦¬ ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
print(f"   - ì „ì²´ ì‹¤í–‰ ì‹œê°„: {hours:02d}:{minutes:02d}:{seconds:02d} ({script_total_time:.2f}ì´ˆ)")
print(f"   - í‰ê·  ì²˜ë¦¬ ì†ë„: {total_processed_rows/total_elapsed:.1f} í–‰/ì´ˆ")
print(f"   - GeoJSON ë¡œë”© ì‹œê°„: {geojson_load_time:.2f}ì´ˆ ({geojson_load_time/script_total_time*100:.1f}%)")
print("="*70)

# âœ… ìš”ì•½ ì €ì¥
summary_df = pd.DataFrame(summary_list)
summary_path = os.path.join(OUTPUT_DIR, "__summary.csv")
summary_df.to_csv(summary_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ“‹ ì „ì²´ ìš”ì•½ ì €ì¥ ì™„ë£Œ â†’ {summary_path}")

# âœ… ìƒì„¸ ì‹œê°„ ë¶„ì„ ì¶œë ¥
print(f"\nğŸ“ˆ ë‹¨ê³„ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ë¶„ì„:")
if len(summary_list) > 0:
    avg_read = sum(s['read_time'] for s in summary_list) / len(summary_list)
    avg_geometry = sum(s['geometry_time'] for s in summary_list) / len(summary_list)
    avg_join = sum(s['join_time'] for s in summary_list) / len(summary_list)
    avg_processing = sum(s['processing_time'] for s in summary_list) / len(summary_list)
    avg_save = sum(s['save_time'] for s in summary_list) / len(summary_list)

    print(f"   - íŒŒì¼ ì½ê¸°: {avg_read:.2f}ì´ˆ")
    print(f"   - ì§€ì˜¤ë©”íŠ¸ë¦¬ ìƒì„±: {avg_geometry:.2f}ì´ˆ")
    print(f"   - ê³µê°„ ì¡°ì¸: {avg_join:.2f}ì´ˆ")
    print(f"   - ë°ì´í„° ì²˜ë¦¬: {avg_processing:.2f}ì´ˆ")
    print(f"   - íŒŒì¼ ì €ì¥: {avg_save:.2f}ì´ˆ")